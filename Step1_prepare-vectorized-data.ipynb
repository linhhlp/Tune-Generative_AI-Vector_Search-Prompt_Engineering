{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6b1cbaa5",
   "metadata": {},
   "source": [
    "# Prepare Data\n",
    "\n",
    "We extract information from HTML websites and vectorize the text. Finally, we save the data to Cassandra DB which supports Vector Search.\n",
    "\n",
    "My similar work can be found at [Convert Text to Vector](https://github.com/linhhlp/Machine-Learning-Applications/tree/main/Text-2-Vect-Vector-Search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55fc5803",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cohere\n",
    "import time\n",
    "import os\n",
    "import uuid\n",
    "import html2text\n",
    "\n",
    "\n",
    "# get free Trial API Key at https://cohere.ai/\n",
    "from cred import API_key\n",
    "\n",
    "co = cohere.Client(API_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a38853b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_text_2_vect(co, texts, model=\"embed-english-light-v2.0\"):\n",
    "    \"\"\"Convert multiple text strings to vectors.\"\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    co : cohere.Client\n",
    "        co = cohere.Client(API_key)\n",
    "    texts : list of strings\n",
    "        texts = [text1, text2, text3, text4, text5, text6...]\n",
    "    model : str, optional\n",
    "        Dimension of output vector, by default \"embed-english-light-v2.0\"\n",
    "        \"embed-english-light-v2.0\" = 1024 dim\n",
    "        \"embed-english-v2.0\" = 4096 dim\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list of vectors\n",
    "        [[0.1, 0.2, 0.3], [0.4, 0.5, 0.6], ... ]\n",
    "    \"\"\"\n",
    "    response = co.embed(model=model, texts=texts)\n",
    "    # print('Embeddings: {}'.format(response.embeddings))\n",
    "    return response.embeddings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ffd92553",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "Original scraped from: https://www.tesla.com/ownersmanual/model3/en_us/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1da649c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "html_dir = \"data/tesla3/html/\"\n",
    "text_dir = \"data/tesla3/txt/\"\n",
    "\n",
    "texts = []\n",
    "htmls = []\n",
    "guids = []\n",
    "links = []\n",
    "for filename in os.listdir(html_dir):\n",
    "    html_filename = os.path.join(html_dir, filename)\n",
    "    # checking if it is a file\n",
    "    if not os.path.isfile(html_filename) or html_filename[-5:] != \".html\":\n",
    "        continue\n",
    "\n",
    "    with open(html_filename) as f: html = f.read()\n",
    "\n",
    "    text_maker = html2text.HTML2Text()\n",
    "    text_maker.ignore_links = True\n",
    "    text_maker.bypass_tables = False\n",
    "    text = text_maker.handle(html)\n",
    "    text = text[:text.find(\"* Model 3 Owner's Manual\")]\n",
    "    \n",
    "    texts.append(text)\n",
    "    htmls.append(html)\n",
    "    guids.append(filename[5:-5])\n",
    "    links.append(\"https://www.tesla.com/ownersmanual/model3/en_us/\"+filename)\n",
    "\n",
    "    text_filename = os.path.join(text_dir, filename[:-4] + \"txt\")\n",
    "    with open(text_filename, 'w') as file:\n",
    "        file.write(text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7d93d1a0",
   "metadata": {},
   "source": [
    "Now let's convert the texts of plot to vectors using API provided by CO.HERE AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dc8a4837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90 4096\n"
     ]
    }
   ],
   "source": [
    "vecs = convert_text_2_vect(co, texts, model=\"embed-english-v2.0\")\n",
    "print(len(vecs), len(vecs[0]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "502a2561",
   "metadata": {},
   "source": [
    "# Save to Cassandra\n",
    "\n",
    "To do Vector Search, I use the Cassandra offerred by DataStax. This gives a free 5GB storage space on Google cloud platform.\n",
    "\n",
    "To authorize, we need to download the secure connect bundle first. The guide is here https://docs.datastax.com/en/astra-serverless/docs/connect/secure-connect-bundle.html\n",
    "\n",
    "After that, create Application tokens: https://docs.datastax.com/en/astra-serverless/docs/manage/org/manage-tokens.html\n",
    "\n",
    "Save this information to `cred.py` following the template in `cred-template.py`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68c59e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cassandra import ConsistencyLevel\n",
    "from cassandra.auth import PlainTextAuthProvider\n",
    "from cassandra.cluster import Cluster\n",
    "\n",
    "from cred import (ASTRA_CLIENT_ID, ASTRA_CLIENT_SECRET,\n",
    "                  SECURE_CONNECT_BUNDLE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc7f2b5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x29aa05497c0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KEYSPACE_NAME = \"demo\"\n",
    "TABLE_NAME = \"car_manual_vectorized\"\n",
    "\n",
    "cloud_config = {\"secure_connect_bundle\": SECURE_CONNECT_BUNDLE_PATH}\n",
    "auth_provider = PlainTextAuthProvider(ASTRA_CLIENT_ID, ASTRA_CLIENT_SECRET)\n",
    "cluster = Cluster(cloud=cloud_config, auth_provider=auth_provider, protocol_version=4)\n",
    "session = cluster.connect()\n",
    "session.execute(f\"USE {KEYSPACE_NAME};\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9f3a2cda",
   "metadata": {},
   "source": [
    "## Prepare Table and Indexes\n",
    "\n",
    "The vector columns must be indexed to fast calculate ANN (Approximate Nearest Neighbor).\n",
    "\n",
    "Based on the input which is a point in space (which has dimension equal to the dim of the vector), the Cassandra will calculate the distances from given point to data in database and return the nearest neighbors using ANN search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f40e7f09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x29aa05e40d0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"year\", 'title', 'director', 'cast', \"genre\", 'plot', \"plot_summary\", 'wiki_link', plot_vector_1024, plot_summary_vector_1024\n",
    "table_create_query = f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {TABLE_NAME} (\n",
    "id uuid,\n",
    "link text,\n",
    "html text,\n",
    "text text,\n",
    "brand text,\n",
    "model text,\n",
    "year int,\n",
    "html_car_vector_4096 VECTOR<FLOAT, 4096>, \n",
    "PRIMARY KEY ((brand, model, year), id)\n",
    ");\n",
    "\"\"\"\n",
    "session.execute(table_create_query)\n",
    "\n",
    "create_index_query = f\"\"\"\n",
    "CREATE CUSTOM INDEX IF NOT EXISTS ann_html_car_vector_4096 ON \n",
    "{TABLE_NAME}(html_car_vector_4096) USING 'StorageAttachedIndex';\n",
    "\"\"\"\n",
    "session.execute(create_index_query)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bda359d2",
   "metadata": {},
   "source": [
    "## Insert to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6e711ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand = \"tesla\"\n",
    "model = \"model3\"\n",
    "year = 2023\n",
    "for i in range(len(texts)):\n",
    "    row = (uuid.UUID(guids[i]), links[i], htmls[i], texts[i], brand, model, year, vecs[i])\n",
    "    session.execute(\n",
    "                    f\"\"\"\n",
    "INSERT INTO {TABLE_NAME} \n",
    "(id, link, html, text, brand, model, year, html_car_vector_4096) \n",
    "VALUES \n",
    "(%s, %s, %s, %s, %s, %s, %s, %s)\n",
    "\"\"\",\n",
    "                    row\n",
    "                )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "20d80a52",
   "metadata": {},
   "source": [
    "The insertion can be speeded up by using Batch processing or upload CSV file in CQL. The demonstration here https://github.com/linhhlp/Big-Data-and-Machine-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea911784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close connection to Cassandra\n",
    "cluster.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
